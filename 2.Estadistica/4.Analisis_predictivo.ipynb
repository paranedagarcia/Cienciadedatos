{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342207f5",
   "metadata": {},
   "source": [
    "# El Análisis Predictivo: Regresión Lineal y Covarianza\n",
    "\n",
    "Una vez que entendemos los datos, podemos empezar a responder preguntas más complejas: ¿Hay una relación entre dos variables? ¿Podemos usar el conocimiento de una variable para predecir otra? Estas preguntas son el núcleo del análisis predictivo, una de las áreas más prácticas y valiosas de la ciencia de datos. Dos de las herramientas estadísticas más fundamentales para explorar relaciones y construir predicciones son la **covarianza** y la **regresión lineal**.\n",
    "\n",
    "## Covarianza\n",
    "\n",
    "La **covarianza** es una medida que cuantifica la dirección de la relación lineal entre dos variables cuantitativas. Específicamente, mide si los cambios en una variable están asociados con cambios en la otra. Una covarianza positiva indica que cuando una variable tiende a aumentar, la otra también lo hace. Una covarianza negativa indica que cuando una variable aumenta, la otra tiende a disminuir. Sin embargo, la principal limitación de la covarianza es que su valor numérico no está estandarizado, por lo que es difícil interpretar la magnitud de la relación; su signo es lo único que realmente importa para la dirección. Por esta razón, se suele utilizar una versión estandarizada de la covarianza: el **coeficiente de correlación de Pearson**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1605f68f",
   "metadata": {},
   "source": [
    "## Análisis de regresión sobre datos\n",
    "El **análisis de regresión** es una técnica estadística utilizada para modelar y analizar la relación entre una variable dependiente (o respuesta) y una o más variables independientes (o predictoras). La forma más simple y común de análisis de regresión es la **regresión lineal simple**, que examina la relación entre dos variables cuantitativas. En la regresión lineal simple, se ajusta una línea recta a los datos que minimiza la suma de los cuadrados de las diferencias entre los valores observados y los valores predichos por el modelo. La ecuación de la línea de regresión se expresa generalmente como:\n",
    "$$ Y = \\beta_0 + \\beta_1 X + \\epsilon $$\n",
    "donde:\n",
    "- $ Y $ es la variable dependiente (lo que queremos predecir).\n",
    "- $X $ es la variable independiente (la que usamos para hacer la predicción).\n",
    "- $ \\beta_0 $ es la intersección (el valor de $ Y $ cuando $ X = 0 $).\n",
    "- $ \\beta_1 $ es la pendiente de la línea (cuánto cambia $ Y $ por un cambio unitario en $ X $).\n",
    "- $ \\epsilon $ es el término de error (la variabilidad en $ Y $ que no puede ser explicada por $ X $).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13151ec",
   "metadata": {},
   "source": [
    "## Regresión Lineal\n",
    "\n",
    "Mientras que la correlación describe una relación existente, la **regresión lineal** va un paso más allá y permite modelar y predecir. La regresión lineal simple se utiliza para modelar la relación entre una variable dependiente (o respuesta, *y*) y una única variable independiente (o predictor, *x*) suponiendo que esa relación es lineal. El objetivo es encontrar la línea recta \"mejor ajustada\" que pasa a través de los puntos de datos en un gráfico de dispersión. Esta línea se describe mediante la ecuación `y = mx + b`, donde `m` es la pendiente (indica cómo cambia *y* por cada unidad de cambio en *x*) y `b` es la intersección en el eje *y*. En el contexto de la inferencia estadística, se construyen intervalos de confianza para la pendiente para determinar si es estadísticamente significativa (es decir, si difiere de cero).\n",
    "\n",
    "La regresión lineal múltiple extiende este concepto para incorporar más de un predictor. Por ejemplo, podríamos querer predecir el precio de una casa (`price`) basándonos en su tamaño (`square_feet`), el número de habitaciones (`bedrooms`) y su antigüedad (`age`). La ecuación se generaliza a `y = b0 + b1*x1 + b2*x2 + ... + bn*xn`. La regresión lineal es un modelo paramétrico que a menudo asume que los residuos (las diferencias entre los valores observados y los predichos por el modelo) se distribuyen normalmente y tienen una varianza constante. Validar estas suposiciones es una parte crítica del proceso de modelado.\n",
    "\n",
    "Estos métodos son la base de muchas aplicaciones en la ciencia de datos. El comercio electrónico utiliza la regresión para analizar la relación entre el tiempo de permanencia en una página y las ventas. Los fabricantes usan el análisis de correlación para identificar factores que influyen en la calidad de un producto. Los economistas utilizan la regresión para modelar la relación entre el gasto en publicidad y las ventas de un producto. El aprendizaje automático y la inteligencia artificial se basan enormemente en estas bases estadísticas para crear modelos predictivos que impulsan sistemas de recomendación, detección de fraudes, diagnóstico médico y mucho más. Entender cómo funcionan la covarianza y la regresión no solo ayuda a analizar datos, sino que también proporciona una comprensión profunda de cómo se construyen muchos de los modelos que impulsan la tecnología moderna."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
